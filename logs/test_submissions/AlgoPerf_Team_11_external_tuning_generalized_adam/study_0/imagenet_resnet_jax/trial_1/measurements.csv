global_step,grad_norm,loss,lr,train/accuracy,train/loss,validation/accuracy,validation/loss,validation/num_examples,test/accuracy,test/loss,test/num_examples,score,total_duration,accumulated_submission_time,accumulated_eval_time,accumulated_logging_time,preemption_count
0,0.53570753,6.93432,0.0,,,,,,,,,,,,,,
1,,,,0.0009765625,6.913403511047363,0.0011399999493733,6.913041591644287,50000.0,0.0015000000130385,6.912566661834717,10000.0,48.26996684074402,84.45480561256409,48.26996684074402,36.18474102020264,0.0,0.0
1,0.5278915,6.9260993,0.00010442734,,,,,,,,,,,,,,
2,0.53617436,6.921964,0.00020885468,,,,,,,,,,,,,,
3,0.5346397,6.9277363,0.0003131628,,,,,,,,,,,,,,
4,0.524459,6.921167,0.00041759014,,,,,,,,,,,,,,
5,0.5394303,6.9295883,0.0005220175,,,,,,,,,,,,,,
6,0.53245777,6.930467,0.0006264448,,,,,,,,,,,,,,
7,0.5381317,6.9234853,0.00073087215,,,,,,,,,,,,,,
8,0.5418048,6.9291368,0.0008351803,,,,,,,,,,,,,,
9,0.5288049,6.9258895,0.0009396076,,,,,,,,,,,,,,
10,,,,0.0008769132546149,6.910956859588623,0.0009800000116229,6.911878108978272,50000.0,0.0006000000284984,6.910926818847656,10000.0,51.30924701690674,106.15387320518494,51.30924701690674,54.81517195701599,0.0286695957183837,0.0
10,,,,,,,,,,,,51.30924701690674,,,,,0.0
