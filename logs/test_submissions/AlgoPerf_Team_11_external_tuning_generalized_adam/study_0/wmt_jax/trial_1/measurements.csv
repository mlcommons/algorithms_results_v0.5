global_step,grad_norm,loss,lr,train/accuracy,train/loss,train/bleu,validation/accuracy,validation/loss,validation/bleu,validation/num_examples,test/accuracy,test/loss,test/bleu,test/num_examples,score,total_duration,accumulated_submission_time,accumulated_eval_time,accumulated_logging_time,preemption_count
0,3.9039047,10.988027,0.0,,,,,,,,,,,,,,,,,
1,,,,0.0005976737011224,10.957541465759276,0.0,0.0004835649742744,10.944228172302246,0.0,3000.0,0.0007088489946909,10.940604209899902,0.0,3003.0,35.95675706863403,921.8839361667632,35.95675706863403,885.9271397590637,0.0,0.0
1,3.831727,10.982607,0.00014615059,,,,,,,,,,,,,,,,,
2,3.9124115,10.970277,0.0002924204,,,,,,,,,,,,,,,,,
3,3.7861538,10.9608965,0.00043845177,,,,,,,,,,,,,,,,,
4,3.7650554,10.926995,0.00058460236,,,,,,,,,,,,,,,,,
5,3.6738262,10.890662,0.00073087215,,,,,,,,,,,,,,,,,
6,3.6022983,10.811421,0.00087702274,,,,,,,,,,,,,,,,,
7,3.3245597,10.748133,0.0010230541,,,,,,,,,,,,,,,,,
8,3.0868654,10.644478,0.0011693239,,,,,,,,,,,,,,,,,
9,2.8624644,10.543059,0.0013154745,,,,,,,,,,,,,,,,,
10,,,,0.000662365113385,10.204434394836426,0.0040297190424063,0.0005331613938324,10.19687557220459,0.0040067245312576,3000.0,0.0007437104359269,10.224416732788086,0.0040499693779494,3003.0,39.25135159492493,1728.6566030979156,39.25135159492493,1689.3746302127838,0.0299611091613769,0.0
10,,,,,,,,,,,,,,,39.25135159492493,,,,,0.0
