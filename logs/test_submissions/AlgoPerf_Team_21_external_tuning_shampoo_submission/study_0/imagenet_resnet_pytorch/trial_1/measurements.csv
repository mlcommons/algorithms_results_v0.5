global_step,grad_norm,loss,train/accuracy,train/loss,validation/accuracy,validation/loss,validation/num_examples,test/accuracy,test/loss,test/num_examples,score,total_duration,accumulated_submission_time,accumulated_eval_time,accumulated_logging_time,preemption_count
0,0.6581369638442993,6.926742076873779,,,,,,,,,,,,,,
1,,,0.0009367028061224,6.922381965481505,0.00108,6.922231875,50000.0,0.0012,6.9256109375,10000.0,113.60319447517396,326.71123242378235,113.60319447517396,212.54839491844177,0.0,0.0
1,0.6753082871437073,6.91965389251709,,,,,,,,,,,,,,
2,0.6764193773269653,6.933249950408936,,,,,,,,,,,,,,
3,0.6800837516784668,6.93456506729126,,,,,,,,,,,,,,
4,0.6623111963272095,6.929059028625488,,,,,,,,,,,,,,
5,0.6580448746681213,6.920506477355957,,,,,,,,,,,,,,
6,0.6760895252227783,6.930760383605957,,,,,,,,,,,,,,
7,0.6875266432762146,6.936650276184082,,,,,,,,,,,,,,
8,0.6784663796424866,6.928768634796143,,,,,,,,,,,,,,
9,0.6924264430999756,6.930497169494629,,,,,,,,,,,,,,
10,,,0.0009566326530612,6.9137554557956,0.00098,6.913981875,50000.0,0.0009,6.9152734375,10000.0,117.04360342025755,421.00859546661377,117.04360342025755,301.76127529144287,0.0349273681640625,0.0
10,,,,,,,,,,,117.04360342025757,,,,,0.0
