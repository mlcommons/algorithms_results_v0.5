global_step,grad_norm,loss,train/accuracy,train/loss,train/bleu,validation/accuracy,validation/loss,validation/bleu,validation/num_examples,test/accuracy,test/loss,test/bleu,test/num_examples,score,total_duration,accumulated_submission_time,accumulated_eval_time,accumulated_logging_time,preemption_count
0,6.712689399719238,12.671029090881348,,,,,,,,,,,,,,,,,
1,,,0.000626166947493,13.109984801220456,3.8311278316580116e-10,0.0004835649898947,13.101077481990304,1.6223815705607103e-08,3000.0,0.0007088489919237,13.120090349195282,1.1313929070166105e-07,3003.0,79.49330711364746,938.8842103481292,79.49330711364746,858.7220094203949,0.0,0.0
1,6.742970943450928,12.67601490020752,,,,,,,,,,,,,,,,,
2,6.824048042297363,12.6674165725708,,,,,,,,,,,,,,,,,
3,6.8917236328125,12.597175598144531,,,,,,,,,,,,,,,,,
4,6.985843658447266,12.516841888427734,,,,,,,,,,,,,,,,,
5,7.074706554412842,12.402044296264648,,,,,,,,,,,,,,,,,
6,7.200223445892334,12.293523788452148,,,,,,,,,,,,,,,,,
7,7.176805019378662,12.12243366241455,,,,,,,,,,,,,,,,,
8,7.06251859664917,11.933234214782717,,,,,,,,,,,,,,,,,
9,6.852154731750488,11.748722076416016,,,,,,,,,,,,,,,,,
10,,,0.0005726720879624,11.40394714236628,4.424210421287586e-07,0.0004835649898947,11.397763976888074,6.083274699866261e-06,3000.0,0.0007088489919237,11.418947184939864,3.0576122339638006e-06,3003.0,83.46929907798767,1785.3794870376587,83.46929907798767,1700.11900806427,0.032623291015625,0.0
10,,,,,,,,,,,,,,83.46929907798767,,,,,0.0
