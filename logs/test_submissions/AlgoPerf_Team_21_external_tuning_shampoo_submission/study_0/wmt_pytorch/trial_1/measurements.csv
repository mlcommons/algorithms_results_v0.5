global_step,grad_norm,loss,train/accuracy,train/loss,train/bleu,validation/accuracy,validation/loss,validation/bleu,validation/num_examples,test/accuracy,test/loss,test/bleu,test/num_examples,score,total_duration,accumulated_submission_time,accumulated_eval_time,accumulated_logging_time,preemption_count
0,7.016944885253906,11.590301513671877,,,,,,,,,,,,,,,,,
1,,,0.000626166947493,11.73867420533722,0.0,0.0004835649898947,11.748467160977546,0.0,3000.0,0.0007088489919237,11.754436116437162,0.0,3003.0,78.56408977508545,936.5619473457336,78.56408977508545,857.4029457569122,0.0,0.0
1,7.080074787139893,11.592720985412598,,,,,,,,,,,,,,,,,
2,6.970922946929932,11.56778335571289,,,,,,,,,,,,,,,,,
3,6.734991073608398,11.50523281097412,,,,,,,,,,,,,,,,,
4,6.379347801208496,11.4207763671875,,,,,,,,,,,,,,,,,
5,5.937037944793701,11.33678913116455,,,,,,,,,,,,,,,,,
6,5.646450519561768,11.225595474243164,,,,,,,,,,,,,,,,,
7,5.112967014312744,11.116540908813477,,,,,,,,,,,,,,,,,
8,4.665352821350098,11.00541877746582,,,,,,,,,,,,,,,,,
9,4.244651794433594,10.898777961730955,,,,,,,,,,,,,,,,,
10,,,0.0005726720879624,10.713045470163785,2.0639501613720127e-11,0.0004835649898947,10.729320622186954,0.0,3000.0,0.0007088489919237,10.75632516994945,0.0,3003.0,82.1916766166687,1778.4092934131622,82.1916766166687,1694.6143844127655,0.0340828895568847,0.0
10,,,,,,,,,,,,,,82.1916766166687,,,,,0.0
