global_step,grad_norm,loss,train/accuracy,train/loss,train/mean_average_precision,validation/accuracy,validation/loss,validation/mean_average_precision,validation/num_examples,test/accuracy,test/loss,test/mean_average_precision,test/num_examples,score,total_duration,accumulated_submission_time,accumulated_eval_time,accumulated_logging_time,preemption_count
0,2.5116248,0.7223511,,,,,,,,,,,,,,,,,
1,,,0.5990074276924133,0.7226627469062805,0.0235707900650298,0.5926870107650757,0.7225216627120972,0.0278320848341565,43793.0,0.5864232182502747,0.725441038608551,0.0300102333566261,43793.0,25.194344758987427,333.1219005584717,25.194344758987427,307.92750883102417,0.0,0.0
1,2.504555,0.7228775,,,,,,,,,,,,,,,,,
2,2.5332484,0.72263914,,,,,,,,,,,,,,,,,
3,2.4881356,0.7198061,,,,,,,,,,,,,,,,,
4,2.4486337,0.7185762,,,,,,,,,,,,,,,,,
5,2.425649,0.7136638,,,,,,,,,,,,,,,,,
6,2.414023,0.7092639,,,,,,,,,,,,,,,,,
7,2.3872125,0.70501125,,,,,,,,,,,,,,,,,
8,2.2861335,0.70019585,,,,,,,,,,,,,,,,,
9,2.1544402,0.69103926,,,,,,,,,,,,,,,,,
10,,,0.6137474179267883,0.6826621890068054,0.0259304342732204,0.6111337542533875,0.6831428408622742,0.0275982664700432,43793.0,0.605924129486084,0.6863194108009338,0.029230812521771,43793.0,28.36761283874512,453.8563787937164,28.36761283874512,425.45733094215393,0.0306801795959472,0.0
10,,,,,,,,,,,,,,28.367612838745117,,,,,0.0
