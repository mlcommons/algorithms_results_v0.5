global_step,grad_norm,loss,train/accuracy,train/loss,train/bleu,validation/accuracy,validation/loss,validation/bleu,validation/num_examples,test/accuracy,test/loss,test/bleu,test/num_examples,score,total_duration,accumulated_submission_time,accumulated_eval_time,accumulated_logging_time,preemption_count
0,6.832947,11.400962,,,,,,,,,,,,,,,,,
1,,,0.000689338252414,11.418046951293944,0.0,0.0004835649742744,11.44489288330078,0.0,3000.0,0.0007088489946909,11.450770378112791,0.0,3003.0,64.91109776496887,957.6471586227416,64.91109776496887,892.7360200881958,0.0,0.0
1,6.855503,11.402311,,,,,,,,,,,,,,,,,
2,6.812924,11.391928,,,,,,,,,,,,,,,,,
3,6.7561073,11.410795,,,,,,,,,,,,,,,,,
4,6.7983403,11.383898,,,,,,,,,,,,,,,,,
5,6.8109365,11.373012,,,,,,,,,,,,,,,,,
6,6.6505785,11.342169,,,,,,,,,,,,,,,,,
7,6.5154366,11.330791,,,,,,,,,,,,,,,,,
8,6.487869,11.316741,,,,,,,,,,,,,,,,,
9,6.375583,11.27603,,,,,,,,,,,,,,,,,
10,,,0.0006405930034816,11.238507270812988,0.0,0.0004835649742744,11.262591361999512,5.862560373098045e-10,3000.0,0.0007088489946909,11.269953727722168,5.587055832900854e-10,3003.0,68.3750958442688,1831.3687295913696,68.3750958442688,1762.96204662323,0.0308649539947509,0.0
10,,,,,,,,,,,,,,68.3750958442688,,,,,0.0
