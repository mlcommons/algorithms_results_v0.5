global_step,grad_norm,loss,train/accuracy,train/loss,train/bleu,validation/accuracy,validation/loss,validation/bleu,validation/num_examples,test/accuracy,test/loss,test/bleu,test/num_examples,score,total_duration,accumulated_submission_time,accumulated_eval_time,accumulated_logging_time,preemption_count
0,7.10250997543335,11.71382999420166,,,,,,,,,,,,,,,,,
1,,,0.000636870237689,11.91738456726942,2.0821826989486302e-10,0.0004835649898947,11.905360751881563,1.587925692574295e-09,3000.0,0.0007088489919237,11.912068589855323,2.530081616601513e-10,3003.0,67.928875207901,956.6041462421416,67.928875207901,888.1423153877258,0.0,0.0
1,7.079284191131592,11.714347839355469,,,,,,,,,,,,,,,,,
2,7.14827299118042,11.717626571655272,,,,,,,,,,,,,,,,,
3,7.101304054260254,11.711139678955078,,,,,,,,,,,,,,,,,
4,7.004622459411621,11.682109832763672,,,,,,,,,,,,,,,,,
5,6.949667930603027,11.671597480773926,,,,,,,,,,,,,,,,,
6,6.96235990524292,11.653870582580566,,,,,,,,,,,,,,,,,
7,6.787477970123291,11.616031646728516,,,,,,,,,,,,,,,,,
8,6.680778980255127,11.56264305114746,,,,,,,,,,,,,,,,,
9,6.358612060546875,11.512845993041992,,,,,,,,,,,,,,,,,
10,,,0.0006170300287947,11.523903486219664,3.8432837332294136e-10,0.0004835649898947,11.5130508301199,3.891314964305664e-09,3000.0,0.0007088489919237,11.52356559758294,0.0,3003.0,71.49636387825012,1830.718663454056,71.49636387825012,1757.5120735168457,0.0319890975952148,0.0
10,,,,,,,,,,,,,,71.49636387825012,,,,,0.0
