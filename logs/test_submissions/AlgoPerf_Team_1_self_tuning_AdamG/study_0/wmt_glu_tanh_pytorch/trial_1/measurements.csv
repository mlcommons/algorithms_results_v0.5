global_step,grad_norm,loss,train/accuracy,train/loss,train/bleu,validation/accuracy,validation/loss,validation/bleu,validation/num_examples,test/accuracy,test/loss,test/bleu,test/num_examples,score,total_duration,accumulated_submission_time,accumulated_eval_time,accumulated_logging_time,preemption_count
0,6.517138481140137,12.768270492553713,,,,,,,,,,,,,,,,,
1,,,0.000636870237689,13.24694216990788,3.3531776209693246e-10,0.0004835649898947,13.23720257653346,7.10877625965521e-10,3000.0,0.0007088489919237,13.263488466678288,5.49587541646279e-10,3003.0,67.40736794471741,964.8867197036744,67.40736794471741,896.918253660202,0.0,0.0
1,6.506698131561279,12.799671173095703,,,,,,,,,,,,,,,,,
2,6.505336761474609,12.789899826049805,,,,,,,,,,,,,,,,,
3,6.554443359375,12.783651351928713,,,,,,,,,,,,,,,,,
4,6.53770112991333,12.754871368408203,,,,,,,,,,,,,,,,,
5,6.593827724456787,12.762234687805176,,,,,,,,,,,,,,,,,
6,6.761641979217529,12.734993934631348,,,,,,,,,,,,,,,,,
7,6.709080696105957,12.711912155151367,,,,,,,,,,,,,,,,,
8,6.82844352722168,12.656787872314451,,,,,,,,,,,,,,,,,
9,6.908213138580322,12.607858657836914,,,,,,,,,,,,,,,,,
10,,,0.0006170300287947,12.801342040312628,5.592708492311927e-08,0.0004835649898947,12.7915664405897,3.816997574731638e-08,3000.0,0.0007088489919237,12.814188600313752,4.317633019986617e-09,3003.0,71.32708978652954,1847.7383801937103,71.32708978652954,1774.5741751194,0.0308856964111328,0.0
10,,,,,,,,,,,,,,71.32708978652954,,,,,0.0
